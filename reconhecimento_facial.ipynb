{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reconhecimento-facial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er83V_f9N9BA"
      },
      "source": [
        "Dependências"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkhFqs7WNy59"
      },
      "source": [
        "import os\r\n",
        "import cv2\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "import numpy as np"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrOBdafVOCVb"
      },
      "source": [
        "Classe Person, representando as imagens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TZr32o0efjq"
      },
      "source": [
        "class Person:\r\n",
        "  def __init__(self, id, label, face):\r\n",
        "    self.id = id\r\n",
        "    self.label = label\r\n",
        "    self.face = face"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C9wDjO2OFRE"
      },
      "source": [
        "Leitura das imagens, conversões e ordenação com base no Id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1wxNj-kQKJy"
      },
      "source": [
        "folder = 'ORL'\r\n",
        "archives = os.listdir(folder)\r\n",
        "\r\n",
        "assert len(archives) == 41 * 10, f'Wrong size of archives, should be {41 * 10}, but actually is {len(archives)}'\r\n",
        "\r\n",
        "persons = []\r\n",
        "\r\n",
        "for archive in archives:\r\n",
        "    split = archive.split(\"_\")\r\n",
        "    id = int(split[0])\r\n",
        "    label = int(split[1].replace('.jpg',''))\r\n",
        "    face = cv2.imread(os.path.join(folder, archive))    \r\n",
        "    face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\r\n",
        "    face = cv2.resize(face, (50, 50))\r\n",
        "    persons.append(Person(id, label, face))\r\n",
        "\r\n",
        "persons.sort(key=lambda person: person.id)"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd6lNBLyOLwh"
      },
      "source": [
        "Separação em lista de treino e teste, usando holdout de 70/30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbEXsSvfTho0"
      },
      "source": [
        "train_persons = list()\r\n",
        "test_persons = list()\r\n",
        "\r\n",
        "for i in range(0, len(persons), 10):\r\n",
        "    person_imgs = persons[i:i + 10]\r\n",
        "    train_person, test_person = train_test_split(person_imgs, train_size = 0.7, test_size = 0.3)\r\n",
        "\r\n",
        "    train_persons += train_person\r\n",
        "    test_persons += test_person"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghLTYAy0OWer"
      },
      "source": [
        "Treinamento do modelo configurando número de componentes principais e teste de acurácia através da predição das faces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WcfET75amj1",
        "outputId": "ea8ba67d-7520-47c0-a325-43c97b4b0222"
      },
      "source": [
        "start_number_of_components = 10\r\n",
        "max_number_of_components = 10\r\n",
        "\r\n",
        "train_persons_faces = [train_person.face for train_person in train_persons]\r\n",
        "train_persons_labels = [train_person.label for train_person in train_persons]\r\n",
        "test_persons_faces = [test_person.face for test_person in test_persons]\r\n",
        "test_persons_labels = [test_person.label for test_person in test_persons]\r\n",
        "\r\n",
        "for number_of_components in range(start_number_of_components, start_number_of_components + max_number_of_components + 1):\r\n",
        "    model = cv2.face.EigenFaceRecognizer_create(number_of_components)  \r\n",
        "    model.train(train_persons_faces, np.array(train_persons_labels))\r\n",
        "\r\n",
        "    prediction = [model.predict(test_person_face)[0] for test_person_face in test_persons_faces]\r\n",
        "    \r\n",
        "    accuracy = accuracy_score(prediction, test_persons_labels) * 100\r\n",
        "    print(f'Com {number_of_components} componentes principais, a acurácia é de {accuracy}%.')"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Com 10 componentes principais, a acurácia é de 94.3089430894309%.\n",
            "Com 11 componentes principais, a acurácia é de 94.3089430894309%.\n",
            "Com 12 componentes principais, a acurácia é de 95.9349593495935%.\n",
            "Com 13 componentes principais, a acurácia é de 94.3089430894309%.\n",
            "Com 14 componentes principais, a acurácia é de 94.3089430894309%.\n",
            "Com 15 componentes principais, a acurácia é de 95.9349593495935%.\n",
            "Com 16 componentes principais, a acurácia é de 95.1219512195122%.\n",
            "Com 17 componentes principais, a acurácia é de 95.9349593495935%.\n",
            "Com 18 componentes principais, a acurácia é de 95.1219512195122%.\n",
            "Com 19 componentes principais, a acurácia é de 95.9349593495935%.\n",
            "Com 20 componentes principais, a acurácia é de 95.9349593495935%.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}